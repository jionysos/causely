# core.py
import os
import json
from datetime import date, timedelta
from typing import Any, Dict, List, Optional, Tuple
# core.pyì— ì¶”ê°€í•  ê²ƒ 1: SQLite ë¡œë“œ + SQL ì‹¤í–‰
import sqlite3

import pandas as pd
from openai import OpenAI
from woe_iv import woe_iv

# core.pyì— ì¶”ê°€í•  ê²ƒ 1: SQLite ë¡œë“œ + SQL ì‹¤í–‰
import sqlite3

def _load_sqlite(orders, items, adj, products) -> sqlite3.Connection:
    conn = sqlite3.connect(":memory:")
    for name, df in [("orders", orders), ("order_items", items), 
                     ("adjustments", adj), ("products", products)]:
        if df is not None and not df.empty:
            df.to_sql(name, conn, index=False, if_exists="replace")
    return conn

def _get_schema(conn: sqlite3.Connection) -> str:
    cursor = conn.cursor()
    cursor.execute("SELECT name FROM sqlite_master WHERE type='table'")
    tables = [r[0] for r in cursor.fetchall()]
    lines = []
    for t in tables:
        cursor.execute(f"PRAGMA table_info({t})")
        cols = ", ".join(f"{c[1]}({c[2]})" for c in cursor.fetchall())
        cursor.execute(f"SELECT * FROM {t} LIMIT 1")
        sample = cursor.fetchone()
        lines.append(f"TABLE {t}: {cols}")
        if sample:
            lines.append(f"  SAMPLE: {sample}")
    return "\n".join(lines)

def _text_to_sql(question: str, schema: str, model: str = "gpt-4o") -> str:
    client = _client()
    resp = client.chat.completions.create(
        model=model,
        messages=[
            {"role": "system", "content": 
             "Return ONLY a SQLite SQL query. No explanation. No markdown.\n"
             "Business context:\n"
             "- order_items.net_sales_amount: íŒë§¤ê¸ˆì•¡\n"
             "- adjustments.amount: í™˜ë¶ˆê¸ˆì•¡(ìŒìˆ˜)\n"
             "- adjustments.reason_code: DEFECT/SIZE/CHANGE_MIND/DELIVERY\n"
             "- order_items.influencer_id: ì¸í”Œë£¨ì–¸ì„œ ID (NULL=ì¼ë°˜êµ¬ë§¤)\n"
             "- order_items.coupon_id: ì¿ í° ID (NULL=ë¯¸ì‚¬ìš©)\n"
             "- products.seller_id: ì…€ëŸ¬ ID"},
            {"role": "user", "content": f"Schema:\n{schema}\n\nQuestion: {question}"}
        ],
        temperature=0
    )
    sql = resp.choices[0].message.content.strip()
    return sql.replace("```sql", "").replace("```", "").strip()

def _context_cell(k: str, v: Any) -> str:
    """Human-readable cell: numbers with thousands sep, rest as-is."""
    if v is None or (isinstance(v, float) and pd.isna(v)):
        return f"{k}: "
    if isinstance(v, (int, float)):
        return f"{k}: {v:,}" if isinstance(v, int) or v == int(v) else f"{k}: {v:,.2f}"
    try:
        n = float(v)
        return f"{k}: {n:,.0f}" if n == int(n) else f"{k}: {n:,.2f}"
    except (TypeError, ValueError):
        pass
    return f"{k}: {v}"


from typing import Dict, Any
import pandas as pd

def build_llm_context(components: Dict[str, Any]) -> str:
    lines = []
    ì¦ê° = components.get("ì¦ê°_ìš”ì•½", {}) or {}
    summary_lines = []

    # --- helpers ---
    def _to_float_pct(v) -> float:
        """ì¦ê°_pctê°€ float/int ë˜ëŠ” '+15.9%' ê°™ì€ ë¬¸ìì—´ì´ì–´ë„ ì•ˆì „í•˜ê²Œ floatë¡œ ë³€í™˜"""
        try:
            if v is None:
                return 0.0
            if isinstance(v, (int, float)):
                return float(v)
            s = str(v).strip()
            s = s.replace("%", "").replace("+", "").replace(" ", "")
            s = s.replace("ì¦ê°€", "").replace("ê°ì†Œ", "").replace("ë™ì¼", "")
            return float(s)
        except Exception:
            return 0.0

    # 0) ë¨¼ì € 'ì´ë§¤ì¶œ ì¦ê°' ë°©í–¥ íŒë‹¨ìš© ê°’ í™•ë³´
    ì´ë§¤ì¶œ_dict = ì¦ê°.get("ì´ë§¤ì¶œ", {}) if isinstance(ì¦ê°, dict) else {}
    ë§¤ì¶œ_pct = _to_float_pct(ì´ë§¤ì¶œ_dict.get("ì¦ê°_pct", 0)) if isinstance(ì´ë§¤ì¶œ_dict, dict) else 0.0

    # 0-1) ì›ì²œ ë°ì´í„°(ë“œë¼ì´ë²„ ê³„ì‚°ìš©) ê°€ì ¸ì˜¤ê¸°
    raw_items = components.get("__raw_items")
    raw_today = components.get("__today")
    raw_compare = components.get("__compare_date")
    raw_products = components.get("__products")

    # 0-2) (ì´ë§¤ì¶œ ì¦ê°€ ì‹œì—ë§Œ) ë§¤ì¶œ ìƒìŠ¹ ë“œë¼ì´ë²„ ë¨¼ì € ê³„ì‚°í•´ë‘ 
    drivers = None
    if (
        ë§¤ì¶œ_pct > 0
        and raw_items is not None
        and raw_today is not None
        and raw_compare is not None
    ):
        try:
            drivers = compute_revenue_uplift_drivers(
                items=raw_items,
                today=raw_today,
                compare_date=raw_compare,
                products=raw_products,
                top_n=5,
            )
        except Exception:
            drivers = None

    # 0) KEY NUMBERS â€” ë³¸ë¬¸ì— ë°˜ë“œì‹œ ì¸ìš©í•  ìˆ˜ì¹˜ (ë§¨ ì•ì— ë°°ì¹˜)
    lines.append("## [í•„ìˆ˜] KEY NUMBERS â€” ì•„ë˜ ìˆ˜ì¹˜ë¥¼ ë³¸ë¬¸ì— ë°˜ë“œì‹œ ë„£ì–´ë¼ (ì—†ìœ¼ë©´ ë¦¬í¬íŠ¸ ì‹¤ê²©)")
    key_nums = []
    for col in ["ì´ë§¤ì¶œ", "ì´ë¹„ìš©", "ìˆœì´ìµ"]:
        v = ì¦ê°.get(col)
        if isinstance(v, dict) and "ì˜¤ëŠ˜" in v and "ê¸°ì¤€ì¼" in v:
            pct = _to_float_pct(v.get("ì¦ê°_pct", 0))
            ë°©í–¥ = "ì¦ê°€" if pct > 0 else "ê°ì†Œ" if pct < 0 else "ë™ì¼"
            key_nums.append(f"{col} ì˜¤ëŠ˜ {v['ì˜¤ëŠ˜']:,}ì› ê¸°ì¤€ì¼ {v['ê¸°ì¤€ì¼']:,}ì› ({pct:+.1f}% {ë°©í–¥})")
            summary_lines.append((col, ë°©í–¥, pct))
    lines.append(" | ".join(key_nums))

    # âœ… (í•µì‹¬) ë§¤ì¶œì´ ì¦ê°€í•œ ê²½ìš°: ë“œë¼ì´ë²„ë¥¼ KEY NUMBERSì— 'í•„ìˆ˜ ì¸ìš©'ìœ¼ë¡œ ë°•ì•„ë²„ë¦¼
    if ë§¤ì¶œ_pct > 0 and drivers:
        must = []
        prod_rows = (drivers.get("product") or [])[:3]
        if prod_rows:
            prod_txt = ", ".join(
                f"{(r.get('name') or r.get('product_id'))} Î”{float(r.get('delta_rev', 0)):,.0f}ì›"
                for r in prod_rows
            )
            must.append(f"ìƒí’ˆ Top3(Î”ë§¤ì¶œ): {prod_txt}")

        ch_rows = (drivers.get("channel") or [])[:2]
        if ch_rows:
            label = "ì±„ë„" if drivers.get("channel_dim") == "channel" else "ì¸í”Œë£¨ì–¸ì„œ"
            ch_txt = ", ".join(
                f"{r.get('channel_value')} Î”{float(r.get('delta_rev', 0)):,.0f}ì›"
                for r in ch_rows
            )
            must.append(f"{label} Top2(Î”ë§¤ì¶œ): {ch_txt}")

        if must:
            lines.append("ë§¤ì¶œ ê²¬ì¸ì(í•„ìˆ˜ ì¸ìš©): " + " | ".join(must))

    # IV Top ì¤„ (âœ… ë§¤ì¶œ ì¦ê°€ ì‹œì—” 'ë³´ì¡°'ë¡œ ê°•ë“±)
    iv_top = components.get("IV_20_ì´ìƒ_ìš”ì¸_ìˆœ", [])[:5]
    if iv_top:
        if ë§¤ì¶œ_pct > 0:
            lines.append("IV ìƒìœ„ ìš”ì¸(ë³´ì¡° ë¶„ì„): " + ", ".join(
                f"{r.get('ìš”ì¸','')}(IV {float(r.get('IV',0)):.1f})" for r in iv_top
            ))
            lines.append("â€» ë§¤ì¶œ ìƒìŠ¹ ì›ì¸ 'ë‹¨ì •'ì€ ë°˜ë“œì‹œ Î”ë§¤ì¶œ(ê²¬ì¸ì) ê¸°ì¤€ìœ¼ë¡œ. IVëŠ” êµ¬ì¡° ë³€í™” ì„¤ëª…(ì™œ) ìš©ë„ë§Œ ì‚¬ìš©.")
        else:
            lines.append("IV ìƒìœ„ ìš”ì¸(ë°˜ë“œì‹œ ë¶„ì„ì— ì‚¬ìš©): " + ", ".join(
                f"{r.get('ìš”ì¸','')}(IV {float(r.get('IV',0)):.1f})" for r in iv_top
            ))
    lines.append("")

    # 1) ì´ë§¤ì¶œÂ·ì´ë¹„ìš©Â·ìˆœì´ìµ ë³€í™” + ë§¥ë½ í•´ì„
    lines.append("## ì´ë§¤ì¶œÂ·ì´ë¹„ìš©Â·ìˆœì´ìµ ë³€í™” (ì˜¤ëŠ˜ vs ê¸°ì¤€ì¼)")
    for col in ["ì´ë§¤ì¶œ", "ì´ë¹„ìš©", "ìˆœì´ìµ"]:
        v = ì¦ê°.get(col)
        if isinstance(v, dict) and "ì˜¤ëŠ˜" in v and "ê¸°ì¤€ì¼" in v:
            pct = _to_float_pct(v.get("ì¦ê°_pct", 0))
            ë°©í–¥ = "ì¦ê°€" if pct > 0 else "ê°ì†Œ" if pct < 0 else "ë™ì¼"
            lines.append(f"- {col}: ì˜¤ëŠ˜ {v['ì˜¤ëŠ˜']:,}ì›, ê¸°ì¤€ì¼ {v['ê¸°ì¤€ì¼']:,}ì› â†’ {ë°©í–¥} ({pct:+.1f}%)")

    ë§¤ì¶œë°©í–¥ = next((s[1] for s in summary_lines if s[0] == "ì´ë§¤ì¶œ"), None)
    ì´ìµë°©í–¥ = next((s[1] for s in summary_lines if s[0] == "ìˆœì´ìµ"), None)
    if ë§¤ì¶œë°©í–¥ == "ì¦ê°€" and ì´ìµë°©í–¥ == "ê°ì†Œ":
        lines.append("âš ï¸ ì£¼ëª© íŒ¨í„´: ë§¤ì¶œì€ ì¦ê°€í–ˆìœ¼ë‚˜ ìˆœì´ìµì´ ê°ì†Œ â†’ ë¹„ìš©Â·í™˜ë¶ˆ ìš”ì¸ ì§‘ì¤‘ ë¶„ì„ í•„ìš” (ë°˜ë“œì‹œ ì‹¬ë„ ë¶„ì„)")
    elif ë§¤ì¶œë°©í–¥ == "ê°ì†Œ" and ì´ìµë°©í–¥ == "ì¦ê°€":
        lines.append("âš ï¸ ì£¼ëª© íŒ¨í„´: ë§¤ì¶œì€ ê°ì†Œí–ˆìœ¼ë‚˜ ìˆœì´ìµì´ ì¦ê°€ â†’ ë¹„ìš© ì ˆê°Â·íš¨ìœ¨í™” íš¨ê³¼ ê°€ëŠ¥ì„± (ë°˜ë“œì‹œ ì‹¬ë„ ë¶„ì„)")
    elif ë§¤ì¶œë°©í–¥ == "ë™ì¼" and ì´ìµë°©í–¥ == "ê°ì†Œ":
        lines.append("âš ï¸ ì£¼ëª© íŒ¨í„´: ë§¤ì¶œì€ ì•ˆì •ì´ë‚˜ ìˆœì´ìµ ê°ì†Œ â†’ ë‚´ë¶€ ìƒì‡„ ìš”ì¸ ì¡´ì¬ ê°€ëŠ¥ì„± (ë°˜ë“œì‹œ ì‹¬ë„ ë¶„ì„)")
    lines.append("â€» ìœ„ì™€ ê°™ì´ 'ë§¤ì¶œâ†‘ ìˆœì´ìµâ†“' ë˜ëŠ” 'ë§¤ì¶œâ†“ ìˆœì´ìµâ†‘' ë“± ì£¼ëª© íŒ¨í„´ì´ ìˆìœ¼ë©´ ë¦¬í¬íŠ¸ì—ì„œ ë°˜ë“œì‹œ ì‹¬ë„ ìˆê²Œ ë¶„ì„í•  ê²ƒ.")
    lines.append("")

    # 1.5) (ì´ë§¤ì¶œ ì¦ê°€ ì‹œì—ë§Œ) ë§¤ì¶œ ìƒìŠ¹ ë“œë¼ì´ë²„ â€” Î”ë§¤ì¶œ(ì›) + êµ¬ì„±ë¹„ ë³€í™”(pp)
    if ë§¤ì¶œ_pct > 0 and drivers:
        lines.append("## ë§¤ì¶œ ìƒìŠ¹ ë“œë¼ì´ë²„ (ì´ë§¤ì¶œ ì¦ê°€ ì‹œì—ë§Œ í‘œì‹œ) â€” Î”ë§¤ì¶œ(ì›) Top + êµ¬ì„±ë¹„ ë³€í™”(pp)")
        lines.append("â€» 'ê²¬ì¸' íŒë‹¨ì€ **Î”ë§¤ì¶œ(ì˜¤ëŠ˜-ê¸°ì¤€ì¼)** ê¸°ì¤€. êµ¬ì„±ë¹„(pp)ëŠ” ë³´ì¡° ì‹ í˜¸(ìˆ˜ìš” êµ¬ì¡° ë³€í™”)ë¡œë§Œ ì‚¬ìš©.")

        # ìƒí’ˆ
        prod_rows = drivers.get("product") or []
        if prod_rows:
            lines.append("### ìƒí’ˆ Top5 (Î”ë§¤ì¶œ ê¸°ì¤€)")
            for r in prod_rows:
                name = r.get("name") or r.get("product_id")
                lines.append(
                    f"- {name} ({r.get('product_id')}): "
                    f"ì˜¤ëŠ˜ {float(r.get('today_rev',0)):,.0f}ì› vs ê¸°ì¤€ì¼ {float(r.get('cmp_rev',0)):,.0f}ì› â†’ "
                    f"Î” {float(r.get('delta_rev',0)):,.0f}ì› | "
                    f"êµ¬ì„±ë¹„ {float(r.get('share_pp',0)):+.1f}pp "
                    f"(count {int(r.get('today_cnt',0))}â†’{int(r.get('cmp_cnt',0))})"
                )

        # ì±„ë„/ì¸í”Œë£¨ì–¸ì„œ
        ch_rows = drivers.get("channel") or []
        ch_dim = drivers.get("channel_dim")
        if ch_rows:
            label = "ì±„ë„" if ch_dim == "channel" else "ì¸í”Œë£¨ì–¸ì„œ(ì±„ë„)" if ch_dim == "influencer_id" else str(ch_dim)
            lines.append(f"### {label} Top5 (Î”ë§¤ì¶œ ê¸°ì¤€)")
            for r in ch_rows:
                v = r.get("channel_value")
                lines.append(
                    f"- {v}: "
                    f"ì˜¤ëŠ˜ {float(r.get('today_rev',0)):,.0f}ì› vs ê¸°ì¤€ì¼ {float(r.get('cmp_rev',0)):,.0f}ì› â†’ "
                    f"Î” {float(r.get('delta_rev',0)):,.0f}ì› | "
                    f"êµ¬ì„±ë¹„ {float(r.get('share_pp',0)):+.1f}pp "
                    f"(count {int(r.get('today_cnt',0))}â†’{int(r.get('cmp_cnt',0))})"
                )
        lines.append("")

    # 2) IV ê¸°ì—¬ë„ ì „ì²´ ìˆœìœ„
    lines.append("## IV ê¸°ì—¬ë„ (ì „ì²´ ìˆœìœ„) â€” IVê°€ ë†’ì„ìˆ˜ë¡ ì˜¤ëŠ˜ ë³€í™”ë¥¼ ë” ë§ì´ ì„¤ëª…í•˜ëŠ” ìš”ì¸")
    iv_ìˆœìœ„ = components.get("IV_ì „ì²´_ìˆœìœ„", components.get("IV_20_ì´ìƒ_ìš”ì¸_ìˆœ", []))
    for r in iv_ìˆœìœ„:
        name = r.get("ìš”ì¸", r.get("name", ""))
        iv = float(r.get("IV", r.get("iv", 0)) or 0)
        ë°©í–¥íŒíŠ¸ = ""
        if "ë¹„ìš©" in name or "í™˜ë¶ˆ" in name:
            ë°©í–¥íŒíŠ¸ = "(ë¹„ìš©/í™˜ë¶ˆ ê³„ì—´: ë†’ìœ¼ë©´ ì§€ì¶œ ë³€í™”ê°€ í° ê²ƒ)"
        elif "ë§¤ì¶œ" in name or "ì¸í”Œë£¨ì–¸ì„œ" in name:
            ë°©í–¥íŒíŠ¸ = "(ë§¤ì¶œ ê³„ì—´: ë†’ìœ¼ë©´ ìˆ˜ìµ ë³€í™”ê°€ í° ê²ƒ)"
        lines.append(f"- [IV {iv:.1f}] {name} {ë°©í–¥íŒíŠ¸}")
    lines.append("")

    # 3) IV 20 ì´ˆê³¼ ìš”ì¸ ìƒì„¸ â€” (ì›ë˜ ë¡œì§ ê·¸ëŒ€ë¡œ ìœ ì§€)
    lines.append("## IV 20 ì´ˆê³¼ ìš”ì¸ ìƒì„¸ (ì „ë¶€)")
    for t in components.get("IV_20_ì´ìƒ_ìƒì„¸_í…Œì´ë¸”", []):
        factor = t.get("factor", "")
        iv = float(t.get("iv", 0) or 0)
        lines.append(f"### ìš”ì¸: {factor} (IV {iv:.1f})")

        summary = t.get("summary", [])
        detail = t.get("detail", [])

        if summary:
            lines.append("  [ìš”ì•½í‘œ] â€” ì˜¤ëŠ˜ vs ê¸°ì¤€ì¼ ìˆ˜ì¹˜ ë³€í™”")
            for row in summary:
                if isinstance(row, dict):
                    row_str = " | ".join(_context_cell(k, v) for k, v in row.items())
                    lines.append(f"    {row_str}")
                else:
                    lines.append(f"    {row}")

            # ìš”ì•½ì—ì„œ ì˜¤ëŠ˜/ê¸°ì¤€ì¼ ìˆ˜ì¹˜ ì¶”ì¶œí•´ì„œ ë°°ìœ¨ ìë™ ê³„ì‚°
            try:
                row = summary[-1] if summary else {}
                gen_t = (
                    abs(float(str(v).replace(",", "")))
                    for k, v in (row.items() if isinstance(row, dict) else {}.items())
                    if "ì˜¤ëŠ˜" in str(k) and v not in [None, 0, ""]
                )
                gen_b = (
                    abs(float(str(v).replace(",", "")))
                    for k, v in (row.items() if isinstance(row, dict) else {}.items())
                    if "ê¸°ì¤€" in str(k) and v not in [None, 0, ""]
                )
                ì˜¤ëŠ˜ê°’ = next(gen_t, None)
                ê¸°ì¤€ê°’ = next(gen_b, None)
                if ì˜¤ëŠ˜ê°’ and ê¸°ì¤€ê°’ and ê¸°ì¤€ê°’ > 0:
                    ë°°ìœ¨ = ì˜¤ëŠ˜ê°’ / ê¸°ì¤€ê°’
                    lines.append(f"  â†’ ì˜¤ëŠ˜ ìˆ˜ì¹˜ê°€ ê¸°ì¤€ì¼ ëŒ€ë¹„ {ë°°ìœ¨:.1f}ë°° ìˆ˜ì¤€")
            except Exception:
                pass

        if detail:
            lines.append("  [ìƒì„¸í‘œ Top5] â€” ê°€ì¥ í° ì˜í–¥ì„ ì¤€ ì„¸ë¶€ í•­ëª©")
            for row in detail:
                if isinstance(row, dict):
                    row_str = " | ".join(_context_cell(k, v) for k, v in row.items())
                    lines.append(f"    {row_str}")
                else:
                    lines.append(f"    {row}")
        lines.append("")

    # 4) ìƒì‡„ íŒ¨í„´ + ì¸ê³¼ê´€ê³„ ìë™ ê°ì§€ (ì›ë˜ ë¡œì§ ìœ ì§€)
    lines.append("## ğŸ” ìë™ ê°ì§€ëœ ì¸ê³¼ê´€ê³„ â€” ë°˜ë“œì‹œ ë¦¬í¬íŠ¸ì— í¬í•¨í•  ê²ƒ")
    try:
        í™˜ë¶ˆ_block = next(
            (t for t in components.get("IV_20_ì´ìƒ_ìƒì„¸_í…Œì´ë¸”", []) if "í™˜ë¶ˆ" in t.get("factor", "")),
            None
        )
        ë§¤ì¶œ_block = next(
            (t for t in components.get("IV_20_ì´ìƒ_ìƒì„¸_í…Œì´ë¸”", []) if "ì¸í”Œë£¨ì–¸ì„œ" in t.get("factor", "")),
            None
        )

        if í™˜ë¶ˆ_block and ë§¤ì¶œ_block:
            top_í™˜ë¶ˆ = next(
                (r for r in í™˜ë¶ˆ_block.get("detail", [])
                 if isinstance(r, dict) and abs(float(str(r.get("ì˜¤ëŠ˜ì í™˜ë¶ˆì•¡", 0)).replace(",", "") or 0)) > 0),
                None
            )
            top_inf = next(
                (r for r in ë§¤ì¶œ_block.get("detail", [])
                 if isinstance(r, dict) and str(r.get("ì¸í”Œë£¨ì–¸ì„œ id", "")).strip() not in ["", "None", "nan"]),
                None
            )

            if top_í™˜ë¶ˆ and top_inf:
                í™˜ë¶ˆê¸ˆ = abs(float(str(top_í™˜ë¶ˆ.get("ì˜¤ëŠ˜ì í™˜ë¶ˆì•¡", 0)).replace(",", "")))
                ë§¤ì¶œê¸ˆ = abs(float(str(top_inf.get("ì˜¤ëŠ˜ì ë§¤ì¶œ", 0)).replace(",", "")))
                pid = top_í™˜ë¶ˆ.get("í™˜ë¶ˆìƒí’ˆ id", "")
                inf_id = str(top_inf.get("ì¸í”Œë£¨ì–¸ì„œ id", "")).strip()

                lines.append(f"- í™˜ë¶ˆ í•µì‹¬ ìƒí’ˆ: {pid} â†’ ì˜¤ëŠ˜ -{í™˜ë¶ˆê¸ˆ:,.0f}ì› (ê¸°ì¤€ì¼ ëŒ€ë¹„ ì‹ ê·œ ë°œìƒ)")
                lines.append(f"- ë§¤ì¶œ í•µì‹¬ ê¸°ì—¬: {inf_id} â†’ ì˜¤ëŠ˜ +{ë§¤ì¶œê¸ˆ:,.0f}ì› (ê¸°ì¤€ì¼ 0ì›ì—ì„œ ì‹ ê·œ ë°œìƒ)")

                if í™˜ë¶ˆê¸ˆ > 0 and ë§¤ì¶œê¸ˆ > 0 and min(í™˜ë¶ˆê¸ˆ, ë§¤ì¶œê¸ˆ) / max(í™˜ë¶ˆê¸ˆ, ë§¤ì¶œê¸ˆ) > 0.7:
                    ì°¨ì´ = abs(í™˜ë¶ˆê¸ˆ - ë§¤ì¶œê¸ˆ)
                    lines.append(
                        f"âš ï¸ ìƒì‡„ êµ¬ì¡° ê°ì§€: {pid} í™˜ë¶ˆ -{í™˜ë¶ˆê¸ˆ:,.0f}ì› ê³¼ {inf_id} ê¸°ì—¬ë§¤ì¶œ +{ë§¤ì¶œê¸ˆ:,.0f}ì› ì˜ ì°¨ì´ê°€ {ì°¨ì´:,.0f}ì›ìœ¼ë¡œ ê±°ì˜ ë™ì¼."
                    )
                    lines.append(
                        f"   â†’ í‘œë©´ ìˆœì´ìµì€ ì•ˆì •ì ìœ¼ë¡œ ë³´ì´ì§€ë§Œ, ì‹¤ì œë¡œëŠ” {pid} í™˜ë¶ˆ ë¬¸ì œê°€ {inf_id} ë§¤ì¶œë¡œ ê°€ë ¤ì§„ êµ¬ì¡°."
                    )
                    lines.append(
                        f"   â†’ ë¦¬í¬íŠ¸ì— ë°˜ë“œì‹œ: 'í‘œë©´ìƒ ìˆœì´ìµ ë³€í™” ì—†ì–´ ë³´ì´ì§€ë§Œ, {pid} í™˜ë¶ˆ(-{í™˜ë¶ˆê¸ˆ:,.0f}ì›)ì„ {inf_id}(+{ë§¤ì¶œê¸ˆ:,.0f}ì›)ê°€ ìƒì‡„í•˜ê³  ìˆëŠ” êµ¬ì¡°. {inf_id} íš¨ê³¼ê°€ ì‚¬ë¼ì§€ë©´ ì¦‰ì‹œ -{í™˜ë¶ˆê¸ˆ:,.0f}ì› ì†ì‹¤ ë…¸ì¶œ' ëª…ì‹œ."
                    )
    except Exception:
        pass

    ìƒí’ˆ_block = next(
        (t for t in components.get("IV_20_ì´ìƒ_ìƒì„¸_í…Œì´ë¸”", []) if "ìƒí’ˆ" in t.get("factor", "")),
        None
    )
    if ìƒí’ˆ_block and ìƒí’ˆ_block.get("detail"):
        lines.append("âš ï¸ ìƒí’ˆ(ìƒí’ˆëª…) IV ìƒì„¸ê°€ ë°ì´í„°ì— ìˆìŒ â†’ KPI ë³€í™” í•µì‹¬ì›ì¸ ë¶„ì„ ë³¸ë¬¸ì— ë°˜ë“œì‹œ ìƒí’ˆë³„ ê¸°ì—¬ ë‚´ìš©(ìƒí’ˆëª…, ì˜¤ëŠ˜ì/ê¸°ì¤€ì¼ ë§¤ì¶œ)ì„ ìˆ˜ì¹˜ì™€ í•¨ê»˜ í¬í•¨í•  ê²ƒ.")

    lines.append("---")
    lines.append("ìœ„ KEY NUMBERSì™€ ìƒì„¸ í‘œì˜ ìˆ˜ì¹˜ë¥¼ ë³¸ë¬¸ì— ë°˜ë“œì‹œ ì¸ìš©í•˜ì—¬ ë¦¬í¬íŠ¸ë¥¼ ì‘ì„±í•˜ë¼. ìˆ«ì ì—†ì´ ì¼ë°˜ë¡ ë§Œ ì“°ë©´ ì‹¤ê²©.")

    return "\n".join(lines)


def _first_day(d: date) -> date:
    return d.replace(day=1)


def _last_day_of_month(d: date) -> date:
    """ë‹¤ìŒ ë‹¬ 1ì¼ - 1ì¼ = ì´ë²ˆ ë‹¬ ë§ˆì§€ë§‰ ë‚ ."""
    next_month = d.replace(day=28) + timedelta(days=4)
    return next_month.replace(day=1) - timedelta(days=1)


def get_monthly_sales_series(
    today: date,
    items: pd.DataFrame,
    adj: pd.DataFrame,
) -> dict:
    """
    ì´ë²ˆ ë‹¬Â·ì§€ë‚œë‹¬ ì¼ë³„ ë§¤ì¶œ ë° ëˆ„ì  ë§¤ì¶œ ê³„ì‚° (today ê¸°ì¤€, í•˜ë“œì½”ë”© ì—†ìŒ).
    ë§¤ì¶œ = order_items net_sales_amount + adjustments amount (í™˜ë¶ˆ ë“±).
    ë°˜í™˜: this_month / last_month ê°ê° daily, cumulative ë¦¬ìŠ¤íŠ¸ (ì¼ì 1~ë§ì¼, ê¸ˆì•¡).
    """
    if "order_ts" not in items.columns or "net_sales_amount" not in items.columns:
        raise ValueError("order_itemsì— order_ts, net_sales_amount ì»¬ëŸ¼ì´ í•„ìš”í•©ë‹ˆë‹¤.")
    if "event_ts" not in adj.columns or "amount" not in adj.columns:
        raise ValueError("adjustmentsì— event_ts, amount ì»¬ëŸ¼ì´ í•„ìš”í•©ë‹ˆë‹¤.")

    items = items.copy()
    adj = adj.copy()
    items["d"] = _to_day(items["order_ts"])
    adj["d"] = _to_day(adj["event_ts"])

    def daily_net(df_items: pd.DataFrame, df_adj: pd.DataFrame, day: date) -> float:
        g = float(df_items.loc[df_items["d"] == day, "net_sales_amount"].sum())
        r = float(df_adj.loc[df_adj["d"] == day, "amount"].sum())
        return g + r

    this_start = _first_day(today)
    this_end = min(today, _last_day_of_month(today))
    last_end = this_start - timedelta(days=1)
    last_start = _first_day(last_end)

    def series_for_range(start: date, end: date):
        days = []
        daily = []
        cum = 0.0
        cumulative = []
        d = start
        while d <= end:
            amt = daily_net(items, adj, d)
            days.append(d.day)
            daily.append(amt)
            cum += amt
            cumulative.append(cum)
            d += timedelta(days=1)
        return {"days": days, "daily": daily, "cumulative": cumulative}

    this_series = series_for_range(this_start, this_end)
    last_series = series_for_range(last_start, last_end)

    return {
        "this_month": this_series,
        "last_month": last_series,
    }


def _client() -> OpenAI:
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        raise RuntimeError(
            "OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤. "
            "í„°ë¯¸ë„ì—ì„œ export OPENAI_API_KEY='...'(ë˜ëŠ” ì‰˜ ì„¤ì • íŒŒì¼ì— ì¶”ê°€) í›„ ë‹¤ì‹œ ì‹¤í–‰í•˜ì„¸ìš”."
        )
    return OpenAI(api_key=api_key)


def _to_day(ts_series: pd.Series) -> pd.Series:
    return pd.to_datetime(ts_series).dt.date


def compute_revenue_uplift_drivers(
    items: pd.DataFrame,
    today: date,
    compare_date: date,
    products: Optional[pd.DataFrame] = None,
    top_n: int = 5,
) -> Dict[str, Any]:
    """
    ì´ë§¤ì¶œì´ 'ì¦ê°€'í•œ ë‚ ì—ë§Œ ì“°ëŠ” ì„¤ëª…ìš© ë“œë¼ì´ë²„.
    - ë©”ì¸: Î”ë§¤ì¶œ(ì˜¤ëŠ˜-ê¸°ì¤€ì¼) TopN (product/channel)
    - ë³´ì¡°: count(distinct order_product_id) êµ¬ì„±ë¹„ ë³€í™”(pp)
    """
    if items is None or items.empty:
        return {}

    it = items.copy()
    if "order_ts" not in it.columns:
        return {}

    it["d"] = _to_day(it["order_ts"])
    it = it[it["d"].isin([today, compare_date])].copy()
    if it.empty:
        return {}

    # í•„ìˆ˜ ê¸ˆì•¡ ì»¬ëŸ¼
    if "net_sales_amount" not in it.columns:
        return {}

    # distinct ê¸°ì¤€: order_product_idê°€ ìˆìœ¼ë©´ ê·¸ê±¸, ì—†ìœ¼ë©´ row count
    distinct_key = "order_product_id" if "order_product_id" in it.columns else None

    def _pick_channel_col(df: pd.DataFrame) -> Optional[str]:
        # "channel"ì´ ìˆìœ¼ë©´ ê·¸ê±¸ ìš°ì„ , ì—†ìœ¼ë©´ influencer_idë¥¼ ì±„ë„ ëŒ€ì²´ë¡œ ì‚¬ìš©
        if "channel" in df.columns:
            return "channel"
        if "influencer_id" in df.columns:
            return "influencer_id"
        return None

    def _agg_dim(df: pd.DataFrame, dim: str) -> pd.DataFrame:
        sub = df[[dim, "d", "net_sales_amount"] + ([distinct_key] if distinct_key else [])].copy()
        sub[dim] = sub[dim].astype(str).replace("nan", "NONE").replace("", "NONE")

        if distinct_key:
            c = sub.groupby(["d", dim])[distinct_key].nunique().rename("cnt").reset_index()
        else:
            c = sub.groupby(["d", dim]).size().rename("cnt").reset_index()

        r = sub.groupby(["d", dim])["net_sales_amount"].sum().rename("rev").reset_index()
        m = pd.merge(r, c, on=["d", dim], how="outer").fillna(0)

        # pivot
        today_m = m[m["d"] == today].set_index(dim)[["rev", "cnt"]].rename(columns={"rev": "today_rev", "cnt": "today_cnt"})
        cmp_m = m[m["d"] == compare_date].set_index(dim)[["rev", "cnt"]].rename(columns={"rev": "cmp_rev", "cnt": "cmp_cnt"})
        idx = sorted(set(today_m.index) | set(cmp_m.index))
        out = pd.concat([today_m.reindex(idx, fill_value=0), cmp_m.reindex(idx, fill_value=0)], axis=1).fillna(0)

        out["delta_rev"] = out["today_rev"] - out["cmp_rev"]
        out["delta_cnt"] = out["today_cnt"] - out["cmp_cnt"]

        total_today_cnt = float(out["today_cnt"].sum()) if float(out["today_cnt"].sum()) != 0 else 1.0
        total_cmp_cnt = float(out["cmp_cnt"].sum()) if float(out["cmp_cnt"].sum()) != 0 else 1.0
        out["share_today"] = out["today_cnt"] / total_today_cnt
        out["share_cmp"] = out["cmp_cnt"] / total_cmp_cnt
        out["share_pp"] = (out["share_today"] - out["share_cmp"]) * 100.0

        # pctëŠ” ë¹„êµê°€ 0ì¼ ë•Œ ì˜ˆì™¸ì²˜ë¦¬
        out["delta_pct"] = out.apply(
            lambda r: (r["delta_rev"] / r["cmp_rev"] * 100.0) if r["cmp_rev"] != 0 else (100.0 if r["delta_rev"] > 0 else 0.0),
            axis=1,
        )

        out = out.sort_values("delta_rev", ascending=False)
        out = out.reset_index().rename(columns={"index": dim})
        return out

    drivers: Dict[str, Any] = {}

    # product
    if "product_id" in it.columns:
        prod_df = _agg_dim(it, "product_id")
        if products is not None and not products.empty and "product_id" in products.columns:
            name_col = "product_name" if "product_name" in products.columns else None
            if name_col:
                name_map = dict(zip(products["product_id"].astype(str), products[name_col].astype(str)))
                prod_df["name"] = prod_df["product_id"].astype(str).map(name_map).fillna(prod_df["product_id"].astype(str))
        else:
            prod_df["name"] = prod_df["product_id"].astype(str)

        drivers["product"] = prod_df.head(top_n).to_dict(orient="records")

    # channel (or influencer)
    ch_col = _pick_channel_col(it)
    if ch_col:
        ch_df = _agg_dim(it, ch_col)
        # unify key name to "channel_value"
        ch_df = ch_df.rename(columns={ch_col: "channel_value"})
        drivers["channel_dim"] = ch_col
        drivers["channel"] = ch_df.head(top_n).to_dict(orient="records")

    return drivers

def compute_sales_strength_factors(
    items: pd.DataFrame,
    today: date,
    compare_date: date,
    min_count: int = 50,
    iv_threshold: float = 20,
) -> List[Dict[str, Any]]:
    """
    order_items ê¸°ì¤€: ê¸°ì¤€ì¼ vs ë¹„êµê¸°ì¤€ì¼ë¡œ (1) product_id, (2) channel, (3) influencer_id ë³„
    order_items ê±´ìˆ˜(í–‰ ìˆ˜) ì§‘ê³„ í›„ woe_ivë¡œ êµ¬ì„±ë¹„ ì°¨ì´ë¥¼ IVë¡œ ê³„ì‚°. ê±´ìˆ˜ min_count ì´ìƒÂ·IV iv_threshold ì´ˆê³¼ë§Œ ë°˜í™˜.
    """
    items = items.copy()
    items["d"] = _to_day(items["order_ts"])
    sub = items[items["d"].isin([today, compare_date])].copy()
    if sub.empty:
        return []
    dimension_config = [
        ("product_id", "ìƒí’ˆ"),
        ("channel", "ì±„ë„"),
        ("influencer_id", "ì¸í”Œë£¨ì–¸ì„œ"),
    ]
    out = []
    for dim_col, dim_label in dimension_config:
        if dim_col not in sub.columns:
            continue
        sub_dim = sub[[dim_col, "d"]].copy()
        sub_dim[dim_col] = sub_dim[dim_col].astype(str).replace("nan", "__NA__").replace("", "__NA__")
        cnt = sub_dim.groupby(dim_col, dropna=False).size()
        valid_vals = cnt[cnt >= min_count].index.tolist()
        if not valid_vals:
            continue
        sub_dim = sub_dim[sub_dim[dim_col].isin(valid_vals)]
        if len(sub_dim) < min_count:
            continue
        data = sub_dim[[dim_col]].copy()
        target = (sub_dim["d"] == today).astype(int)
        try:
            WoE, IV_df = woe_iv(data, target, bins=min(50, max(2, len(valid_vals))))
            if IV_df is None or IV_df.empty:
                continue
            total_iv = float(IV_df["IV"].iloc[0])
            if total_iv <= iv_threshold:
                continue
            woe_var = WoE[WoE["Var_name"] == dim_col].copy()
            woe_var = woe_var.sort_values("IV", ascending=False)
            detail = [
                {"value": str(row["Cut_off"]), "iv_contribution": round(float(row["IV"]), 2)}
                for _, row in woe_var.head(10).iterrows()
            ]
            out.append({
                "dimension": dim_col,
                "dimension_label": dim_label,
                "iv": round(total_iv, 2),
                "detail": detail,
            })
        except Exception:
            continue
    out.sort(key=lambda x: -x["iv"])
    return out


def get_comparison_kpis(
    today: date,
    n_days: int,
    items: pd.DataFrame,
    adj: pd.DataFrame,
) -> dict:
    """
    D-0(ì˜¤ëŠ˜) vs D-n(ë¹„êµì¼) ì¼ë³„ KPI ê³„ì‚°.
    n_days: 1, 7, 28 ë“±. ë¹„êµì¼ = today - n_days.
    ë°˜í™˜: base_date, compare_date, n_days, kpis { net, gross, refund, marketing } ê°ê°
    current, compare, delta, pct.
    """
    compare_date = today - timedelta(days=n_days)
    items = items.copy()
    adj = adj.copy()
    items["d"] = _to_day(items["order_ts"])
    adj["d"] = _to_day(adj["event_ts"])

    def _sum_items(df: pd.DataFrame, d: date, col: str = "net_sales_amount") -> float:
        return float(df.loc[df["d"] == d, col].sum())

    def _sum_adj(df: pd.DataFrame, d: date) -> float:
        return float(df.loc[df["d"] == d, "amount"].sum())

    gross_current = _sum_items(items, today)
    gross_compare = _sum_items(items, compare_date)
    refund_current = _sum_adj(adj, today)
    refund_compare = _sum_adj(adj, compare_date)
    net_current = gross_current + refund_current
    net_compare = gross_compare + refund_compare

    # ë§ˆì¼€íŒ…ë§¤ì¶œ: ì¸í”Œë£¨ì–¸ì„œ ë“± (influencer_idê°€ ìˆëŠ” ì£¼ë¬¸)
    influencer_col = "influencer_id"
    if influencer_col in items.columns:
        it = items[items[influencer_col].notna() & (items[influencer_col].astype(str).str.strip() != "")]
        m_current = float(it.loc[it["d"] == today, "net_sales_amount"].sum())
        m_compare = float(it.loc[it["d"] == compare_date, "net_sales_amount"].sum())
    else:
        m_current = m_compare = 0.0

    def _row(current: float, compare: float) -> dict:
        delta = current - compare
        if compare != 0:
            pct = round((delta / abs(compare)) * 100, 1)
        else:
            pct = 100.0 if delta > 0 else (0.0 if delta == 0 else -100.0)
        return {"current": current, "compare": compare, "delta": delta, "pct": pct}

    return {
        "base_date": str(today),
        "compare_date": str(compare_date),
        "n_days": n_days,
        "kpis": {
            "net": _row(net_current, net_compare),
            "gross": _row(gross_current, gross_compare),
            "refund": _row(refund_current, refund_compare),
            "marketing": _row(m_current, m_compare),
        },
    }


def get_top_three_metrics(
    today: date,
    n_days: int,
    items: pd.DataFrame,
    adj: pd.DataFrame,
) -> dict:
    """
    ìƒë‹¨ 3ì§€í‘œ: ë§¤ì¶œ(ì´ë§¤ì¶œ), ë¹„ìš©(í™˜ë¶ˆ ì ˆëŒ€ê°’+ì¿ í°), ì†ìµë¹„ìœ¨(ì´ìµ/ë¹„ìš©).
    ê° current, compare, delta, pct ë°˜í™˜.
    """
    compare_date = today - timedelta(days=n_days)
    items = items.copy()
    adj = adj.copy()
    items["d"] = _to_day(items["order_ts"])
    adj["d"] = _to_day(adj["event_ts"])

    def _gross(d: date) -> float:
        return float(items.loc[items["d"] == d, "net_sales_amount"].sum())

    def _refund(d: date) -> float:
        return float(adj.loc[adj["d"] == d, "amount"].sum())

    def _coupon(d: date) -> float:
        if "discount_amount" not in items.columns:
            return 0.0
        return float(items.loc[items["d"] == d, "discount_amount"].sum())

    ë§¤ì¶œ_cur = _gross(today)
    ë§¤ì¶œ_cmp = _gross(compare_date)
    refund_cur = _refund(today)
    refund_cmp = _refund(compare_date)
    coupon_cur = _coupon(today)
    coupon_cmp = _coupon(compare_date)
    ë¹„ìš©_cur = abs(refund_cur) + coupon_cur
    ë¹„ìš©_cmp = abs(refund_cmp) + coupon_cmp
    ì´ìµ_cur = ë§¤ì¶œ_cur - ë¹„ìš©_cur
    ì´ìµ_cmp = ë§¤ì¶œ_cmp - ë¹„ìš©_cmp
    ì†ìµë¹„ìœ¨_cur = (ì´ìµ_cur / ë¹„ìš©_cur * 100) if ë¹„ìš©_cur != 0 else 0.0
    ì†ìµë¹„ìœ¨_cmp = (ì´ìµ_cmp / ë¹„ìš©_cmp * 100) if ë¹„ìš©_cmp != 0 else 0.0

    def _row(c: float, p: float) -> dict:
        d = c - p
        pct = round((d / p) * 100, 1) if p != 0 else (100.0 if d > 0 else 0.0)
        return {"current": c, "compare": p, "delta": d, "pct": pct}

    return {
        "base_date": str(today),
        "compare_date": str(compare_date),
        "n_days": n_days,
        "ë§¤ì¶œ": _row(ë§¤ì¶œ_cur, ë§¤ì¶œ_cmp),
        "ë¹„ìš©": _row(ë¹„ìš©_cur, ë¹„ìš©_cmp),
        "ì†ìµë¹„ìœ¨": _row(ì†ìµë¹„ìœ¨_cur, ì†ìµë¹„ìœ¨_cmp),
    }


def get_sales_decomposition(
    today: date,
    n_days: int,
    items: pd.DataFrame,
    orders: pd.DataFrame,
) -> dict:
    """
    ë§¤ì¶œ = ìœ ì…ëŸ‰(ì£¼ë¬¸ìˆ˜) Ã— ì „í™˜ìœ¨(1) Ã— ê°ë‹¨ê°€ ë¡œ ìª¼ê°œì„œ,
    ì „ì²´ ë§¤ì¶œ ë³€ë™ì— ëŒ€í•œ ê¸°ì—¬ë„ ë¶„ì„. (ìœ ì…ëŸ‰ì€ ì£¼ë¬¸ìˆ˜ë¡œ ê·¼ì‚¬, ì „í™˜ìœ¨=1)
    ë°˜í™˜: current/compare for revenue, order_count, aov; contrib_orders, contrib_aov;
    main_driver ("ì£¼ë¬¸ìˆ˜" | "ê°ë‹¨ê°€"), main_driver_contrib_pct.
    """
    compare_date = today - timedelta(days=n_days)
    items = items.copy()
    orders = orders.copy()
    items["d"] = _to_day(items["order_ts"])
    if "order_ts" in orders.columns and orders["order_ts"].notna().any():
        orders["d"] = _to_day(orders["order_ts"])
    elif "order_id" in orders.columns and "order_id" in items.columns:
        order_dates = items.groupby("order_id")["d"].first()
        orders["d"] = orders["order_id"].map(order_dates)
    else:
        orders["d"] = pd.NaT

    def _revenue(d: date) -> float:
        return float(items.loc[items["d"] == d, "net_sales_amount"].sum())

    def _order_count(d: date) -> float:
        return float(orders.loc[orders["d"] == d, "order_id"].nunique())

    def _items_count(d: date) -> float:
        return float((items["d"] == d).sum())

    r0 = _revenue(compare_date)
    r1 = _revenue(today)
    n0 = _order_count(compare_date)
    n1 = _order_count(today)
    i0 = _items_count(compare_date)
    i1 = _items_count(today)
    if n0 == 0:
        aov0 = 0.0
        conv0 = 0.0
    else:
        aov0 = r0 / n0
        conv0 = i0 / n0
    if n1 == 0:
        aov1 = 0.0
        conv1 = 0.0
    else:
        aov1 = r1 / n1
        conv1 = i1 / n1

    delta_r = r1 - r0
    contrib_aov = n0 * (aov1 - aov0)
    contrib_orders = (n1 - n0) * aov1
    if abs(delta_r) < 1e-9:
        main_driver = "ë™ì¼"
        main_driver_contrib_pct = 0.0
    else:
        if abs(contrib_orders) >= abs(contrib_aov):
            main_driver = "ì£¼ë¬¸ìˆ˜"
            main_driver_contrib_pct = round((contrib_orders / delta_r) * 100, 1)
        else:
            main_driver = "ê°ë‹¨ê°€"
            main_driver_contrib_pct = round((contrib_aov / delta_r) * 100, 1)

    def _row(c: float, p: float) -> dict:
        d = c - p
        pct = round((d / p) * 100, 1) if p != 0 else (100.0 if d > 0 else 0.0)
        return {"current": c, "compare": p, "delta": d, "pct": pct}

    return {
        "base_date": str(today),
        "compare_date": str(compare_date),
        "n_days": n_days,
        "revenue": {"current": r1, "compare": r0, "delta": delta_r},
        "order_count": {"current": n1, "compare": n0, "delta": n1 - n0},
        "aov": {"current": aov1, "compare": aov0, "delta": aov1 - aov0},
        "conversion": _row(conv1, conv0),
        "ìœ ì…ëŸ‰": _row(n1, n0),
        "ì „í™˜ìœ¨": _row(conv1, conv0),
        "ê°ë‹¨ê°€": _row(aov1, aov0),
        "contrib_orders": contrib_orders,
        "contrib_aov": contrib_aov,
        "main_driver": main_driver,
        "main_driver_contrib_pct": main_driver_contrib_pct,
    }


def get_sales_narrative(decomp: dict) -> str:
    """
    ë§¤ì¶œ ë¶„í•´ ê²°ê³¼ë¡œ í•œ ë¬¸ì¥ ë‚´ëŸ¬í‹°ë¸Œ.
    ì˜ˆ: "ë§¤ì¶œì€ 5% ì˜¬ëì§€ë§Œ, ì „í™˜ìœ¨ì´ 10% ê¸‰ë½í–ˆìŠµë‹ˆë‹¤. ìœ ì…ëŸ‰ì´ 20% í­ì¦í•´ì„œ..."
    """
    r = decomp["revenue"]
    rev_pct = round((r["delta"] / r["compare"]) * 100, 1) if r["compare"] != 0 else 0
    ìœ ì… = decomp["ìœ ì…ëŸ‰"]
    ì „í™˜ = decomp["ì „í™˜ìœ¨"]
    ê°ë‹¨ê°€ = decomp["ê°ë‹¨ê°€"]
    main = decomp["main_driver"]
    if decomp["main_driver"] == "ë™ì¼":
        return "ë§¤ì¶œê³¼ êµ¬ì„± ì§€í‘œê°€ ë¹„êµì¼ê³¼ ë™ì¼í•©ë‹ˆë‹¤."
    rev_up = rev_pct > 0
    conv_drop = ì „í™˜["pct"] < -5
    inflow_surge = ìœ ì…["pct"] > 10
    parts = []
    parts.append(f"ë§¤ì¶œì€ {rev_pct:+.1f}% {'ì˜¬ëìŠµë‹ˆë‹¤' if rev_up else 'ë‚´ë ¸ìŠµë‹ˆë‹¤'}")
    if conv_drop:
        parts.append(f"ì „í™˜ìœ¨(ì£¼ë¬¸ë‹¹ ìƒí’ˆìˆ˜)ì´ {ì „í™˜['pct']:+.1f}% ê¸‰ë½í–ˆìŠµë‹ˆë‹¤")
    if inflow_surge and conv_drop:
        parts.append(f"ìœ ì…ëŸ‰(ì£¼ë¬¸ìˆ˜)ì´ {ìœ ì…['pct']:+.1f}% ëŠ˜ì–´ë‚˜ ë§¤ì¶œ í•˜ë½ì„ ê²¨ìš° ë§‰ê³  ìˆëŠ” ìœ„í—˜í•œ ìƒí™©ì…ë‹ˆë‹¤")
    elif inflow_surge:
        parts.append(f"ìœ ì…ëŸ‰ì´ {ìœ ì…['pct']:+.1f}% í­ì¦í–ˆìŠµë‹ˆë‹¤")
    if ê°ë‹¨ê°€["pct"] <= -10:
        parts.append(f"ê°ë‹¨ê°€ê°€ {ê°ë‹¨ê°€['pct']:+.1f}% í•˜ë½í–ˆìŠµë‹ˆë‹¤")
    if not parts[1:]:
        parts.append(f"ê°€ì¥ í° ìš”ì¸ì€ **{main}**ì…ë‹ˆë‹¤ (ê¸°ì—¬ë„ ì•½ {abs(decomp['main_driver_contrib_pct']):.1f}%)")
    return "ì‚¬ì¥ë‹˜, " + ". ".join(parts) + "."


def get_14day_series(
    today: date,
    items: pd.DataFrame,
    orders: pd.DataFrame,
    metric: str,
) -> list:
    """
    ìµœê·¼ 14ì¼ ì¼ë³„ ì‹œê³„ì—´. metric: "order_count" | "aov" | "conversion"
    ë°˜í™˜: [{"date": str, "value": float}, ...] (ê³¼ê±°â†’ì˜¤ëŠ˜ ìˆœ).
    """
    items = items.copy()
    orders = orders.copy()
    items["d"] = _to_day(items["order_ts"])
    if "order_ts" in orders.columns and orders["order_ts"].notna().any():
        orders["d"] = _to_day(orders["order_ts"])
    elif "order_id" in orders.columns and "order_id" in items.columns:
        order_dates = items.groupby("order_id")["d"].first()
        orders["d"] = orders["order_id"].map(order_dates)
    else:
        orders["d"] = pd.NaT

    start = today - timedelta(days=13)
    out = []
    for i in range(14):
        d = start + timedelta(days=i)
        rev = float(items.loc[items["d"] == d, "net_sales_amount"].sum())
        n = float(orders.loc[orders["d"] == d, "order_id"].nunique())
        cnt = float((items["d"] == d).sum())
        if metric == "order_count":
            val = n
        elif metric == "aov":
            val = rev / n if n else 0.0
        else:
            val = cnt / n if n else 0.0
        out.append({"date": str(d), "value": round(val, 2)})
    return out


def get_worst_dropped_metric(decomp: dict) -> str:
    """ê¸°ì—¬ë„/ì „í™˜ìœ¨ ì¤‘ ê°€ì¥ í¬ê²Œ ë–¨ì–´ì§„ ì§€í‘œ í‚¤ (14ì¼ ì°¨íŠ¸ìš©)."""
    ìœ ì… = decomp["ìœ ì…ëŸ‰"]
    ì „í™˜ = decomp["ì „í™˜ìœ¨"]
    ê°ë‹¨ê°€ = decomp["ê°ë‹¨ê°€"]
    candidates = [
        ("order_count", ìœ ì…["pct"]),
        ("conversion", ì „í™˜["pct"]),
        ("aov", ê°ë‹¨ê°€["pct"]),
    ]
    worst = min(candidates, key=lambda x: x[1])
    return worst[0]


def get_focus_summary(
    today: date,
    n_days: int,
    items: pd.DataFrame,
    adj: pd.DataFrame,
    products: pd.DataFrame,
    orders: pd.DataFrame,
) -> dict:
    """
    ì „ì¼ ëŒ€ë¹„ ë³€ë™í­ì´ í° ìƒìœ„ 3ê°œ ìƒí’ˆ, ìƒìœ„ 2ê°œ ì±„ë„(ì¸í”Œë£¨ì–¸ì„œ)ë§Œ ìš”ì•½.
    'ì‚¬ì¥ë‹˜, ì—¬ê¸°ë§Œ ë³´ì„¸ìš”'ìš©.
    """
    compare_date = today - timedelta(days=n_days)
    items = items.copy()
    items["d"] = _to_day(items["order_ts"])

    # ìƒí’ˆë³„ ë§¤ì¶œ (order_itemsì— product_id ìˆìœ¼ë©´)
    top_3_products = []
    if "product_id" in items.columns:
        g_today = items[items["d"] == today].groupby("product_id")["net_sales_amount"].sum()
        g_compare = items[items["d"] == compare_date].groupby("product_id")["net_sales_amount"].sum()
        idx = sorted(set(g_today.index) | set(g_compare.index))
        delta = (g_today.reindex(idx, fill_value=0) - g_compare.reindex(idx, fill_value=0)).reindex(idx, fill_value=0)
        delta = delta.sort_values(ascending=True)
        # ë³€ë™í­ í° ìˆœ: ì ˆëŒ€ê°’ ê¸°ì¤€ ìƒìœ„ 3
        by_abs = delta.reindex(delta.abs().sort_values(ascending=False).index)
        for pid in by_abs.head(3).index:
            cur = float(g_today.reindex([pid], fill_value=0).iloc[0])
            cmp = float(g_compare.reindex([pid], fill_value=0).iloc[0])
            d = float(delta.reindex([pid], fill_value=0).iloc[0])
            pct = round((d / cmp) * 100, 1) if cmp != 0 else (100.0 if d > 0 else 0.0)
            name = pid
            if products is not None and "product_id" in products.columns and "product_name" in products.columns:
                p = products[products["product_id"] == pid]
                if len(p):
                    name = p.iloc[0].get("product_name", pid)
            top_3_products.append({"product_id": pid, "name": name, "current": cur, "compare": cmp, "delta": d, "pct": pct})

    # ì±„ë„(ì¸í”Œë£¨ì–¸ì„œ)ë³„ ë§¤ì¶œ, ìƒìœ„ 2ê°œ
    top_2_channels = []
    influencer_col = "influencer_id"
    if influencer_col in items.columns:
        it = items.copy()
        it[influencer_col] = it[influencer_col].fillna("NONE")
        g_today = it[it["d"] == today].groupby(influencer_col)["net_sales_amount"].sum()
        g_compare = it[it["d"] == compare_date].groupby(influencer_col)["net_sales_amount"].sum()
        idx = sorted(set(g_today.index) | set(g_compare.index))
        delta = (g_today.reindex(idx, fill_value=0) - g_compare.reindex(idx, fill_value=0)).reindex(idx, fill_value=0)
        delta = delta[delta.index != "NONE"].sort_values(ascending=False)
        by_abs = delta.reindex(delta.abs().sort_values(ascending=False).index)
        for ch in by_abs.head(2).index:
            cur = float(g_today.reindex([ch], fill_value=0).iloc[0])
            cmp = float(g_compare.reindex([ch], fill_value=0).iloc[0])
            d = float(delta.reindex([ch], fill_value=0).iloc[0])
            pct = round((d / cmp) * 100, 1) if cmp != 0 else (100.0 if d > 0 else 0.0)
            top_2_channels.append({"channel": str(ch), "current": cur, "compare": cmp, "delta": d, "pct": pct})

    return {"top_3_products": top_3_products, "top_2_channels": top_2_channels}


def get_cause_summary(kpis: dict) -> str:
    """
    ìˆœë§¤ì¶œ ë³€ë™ì˜ í•µì‹¬ ì›ì¸ í•œ ë¬¸ì¥.
    í•˜ë½ ì‹œ: ê°€ì¥ í¬ê²Œ ê¸°ì—¬í•œ í•˜ìœ„ ìš”ì¸(ì´ë§¤ì¶œ/í™˜ë¶ˆ)ê³¼ ì¦ê°ë¥ .
    ìƒìŠ¹ ì‹œ: ê°€ì¥ í¬ê²Œ ê¸°ì—¬í•œ ìš”ì¸ê³¼ ì¦ê°ë¥ .
    """
    net = kpis["kpis"]["net"]
    gross = kpis["kpis"]["gross"]
    refund = kpis["kpis"]["refund"]
    net_delta = net["delta"]
    gross_delta = gross["delta"]
    refund_delta = refund["delta"]

    if net_delta == 0:
        return "ì‚¬ì¥ë‹˜, ì˜¤ëŠ˜ ìˆœë§¤ì¶œì€ ë¹„êµ ê¸°ê°„ê³¼ ë™ì¼í•©ë‹ˆë‹¤."

    if net_delta < 0:
        # ìˆœë§¤ì¶œ í•˜ë½: ì´ë§¤ì¶œ í•˜ë½ vs í™˜ë¶ˆ ì¦ê°€(ìŒìˆ˜ í™•ëŒ€) ì¤‘ ë” í° ê¸°ì—¬
        if abs(gross_delta) >= abs(refund_delta):
            factor, pct = "ì´ë§¤ì¶œ", gross["pct"]
            return f"ì‚¬ì¥ë‹˜, ì˜¤ëŠ˜ ìˆœë§¤ì¶œ í•˜ë½ì˜ í•µì‹¬ ì›ì¸ì€ **ì´ë§¤ì¶œ**ì˜ {pct:+.1f}% í•˜ë½ ë•Œë¬¸ì…ë‹ˆë‹¤."
        else:
            factor, pct = "í™˜ë¶ˆ", refund["pct"]
            return f"ì‚¬ì¥ë‹˜, ì˜¤ëŠ˜ ìˆœë§¤ì¶œ í•˜ë½ì˜ í•µì‹¬ ì›ì¸ì€ **í™˜ë¶ˆ**ì˜ {abs(pct):.1f}% ì¦ê°€ ë•Œë¬¸ì…ë‹ˆë‹¤."
    else:
        if abs(gross_delta) >= abs(refund_delta):
            pct = gross["pct"]
            return f"ì‚¬ì¥ë‹˜, ì˜¤ëŠ˜ ìˆœë§¤ì¶œ ìƒìŠ¹ì˜ í•µì‹¬ ìš”ì¸ì€ **ì´ë§¤ì¶œ**ì˜ {pct:+.1f}% ì¦ê°€ ë•Œë¬¸ì…ë‹ˆë‹¤."
        else:
            pct = refund["pct"]
            return f"ì‚¬ì¥ë‹˜, ì˜¤ëŠ˜ ìˆœë§¤ì¶œ ìƒìŠ¹ì˜ í•µì‹¬ ìš”ì¸ì€ **í™˜ë¶ˆ**ì˜ {abs(pct):.1f}% ê°ì†Œ ë•Œë¬¸ì…ë‹ˆë‹¤."


def build_evidence(
    today: date,
    orders: pd.DataFrame,
    items: pd.DataFrame,
    adj: pd.DataFrame,
    products: pd.DataFrame,
    compare_date: Optional[date] = None,
) -> dict:
    """
    Evidence packet ìƒì„±: KPI ë° ë“œë¼ì´ë²„.
    compare_dateê°€ Noneì´ë©´ ì „ì¼(today-1), ì•„ë‹ˆë©´ í•´ë‹¹ ë¹„êµì¼ ì‚¬ìš©.
    """
    yday = (today - timedelta(days=1)) if compare_date is None else compare_date

    items = items.copy()
    adj = adj.copy()

    # ë‚ ì§œ ì»¬ëŸ¼ íŒŒì‹±
    if "order_ts" not in items.columns:
        raise ValueError("order_items.csvì— order_ts ì»¬ëŸ¼ì´ í•„ìš”í•©ë‹ˆë‹¤.")
    if "event_ts" not in adj.columns:
        raise ValueError("adjustments.csvì— event_ts ì»¬ëŸ¼ì´ í•„ìš”í•©ë‹ˆë‹¤.")

    items["d"] = _to_day(items["order_ts"])
    adj["d"] = _to_day(adj["event_ts"])

    # KPI ê³„ì‚°
    if "net_sales_amount" not in items.columns:
        raise ValueError("order_items.csvì— net_sales_amount ì»¬ëŸ¼ì´ í•„ìš”í•©ë‹ˆë‹¤.")
    if "amount" not in adj.columns:
        raise ValueError("adjustments.csvì— amount ì»¬ëŸ¼ì´ í•„ìš”í•©ë‹ˆë‹¤.")

    gross_today = float(items.loc[items["d"] == today, "net_sales_amount"].sum())
    gross_yday = float(items.loc[items["d"] == yday, "net_sales_amount"].sum())

    refund_today = float(adj.loc[adj["d"] == today, "amount"].sum())  # ìŒìˆ˜
    refund_yday = float(adj.loc[adj["d"] == yday, "amount"].sum())

    net_today = gross_today + refund_today
    net_yday = gross_yday + refund_yday

    # Driver 1) Gross ì¦ê°€ Top: influencer_id ê¸°ì¤€
    influencer_col = "influencer_id"
    if influencer_col in items.columns:
        it = items.copy()
        it[influencer_col] = it[influencer_col].fillna("NONE")

        g_today = it[it["d"] == today].groupby(influencer_col)["net_sales_amount"].sum()
        g_yday = it[it["d"] == yday].groupby(influencer_col)["net_sales_amount"].sum()

        idx = sorted(set(g_today.index) | set(g_yday.index))
        g_delta = (g_today.reindex(idx, fill_value=0) - g_yday.reindex(idx, fill_value=0)).sort_values(
            ascending=False
        )

        gross_top = (
            g_delta[g_delta.index != "NONE"]
            .head(5)
            .reset_index()
            .rename(columns={0: "delta_gross", "net_sales_amount": "delta_gross"})
        )
        # pandas ë²„ì „ì— ë”°ë¼ ì»¬ëŸ¼ëª…ì´ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆì–´ì„œ ê°•ì œ
        if gross_top.columns.tolist() == [influencer_col, 0]:
            gross_top.columns = [influencer_col, "delta_gross"]

        gross_top = gross_top.to_dict(orient="records")
    else:
        gross_top = []

    # Driver 2) Refund ì•…í™” Top: product_id ê¸°ì¤€ (ë” ìŒìˆ˜ë¡œ ê°€ëŠ” deltaê°€ ì•…í™”)
    if "product_id" in adj.columns and "product_id" in products.columns:
        r_today = adj[adj["d"] == today].groupby("product_id")["amount"].sum()
        r_yday = adj[adj["d"] == yday].groupby("product_id")["amount"].sum()

        idx = sorted(set(r_today.index) | set(r_yday.index))
        r_delta = (r_today.reindex(idx, fill_value=0) - r_yday.reindex(idx, fill_value=0)).sort_values()
        refund_top_raw = r_delta.head(5).reset_index()
        refund_top_raw.columns = ["product_id", "delta_refund"]

        refund_top = []
        for _, row in refund_top_raw.iterrows():
            if float(row["delta_refund"]) >= 0:
                continue
            pid = row["product_id"]
            p_rows = products[products["product_id"] == pid]
            pinfo = p_rows.iloc[0].to_dict() if len(p_rows) else {}

            # reason_code breakdown (ìˆìœ¼ë©´)
            reasons = []
            if "reason_code" in adj.columns:
                reasons = (
                    adj[(adj["d"] == today) & (adj["product_id"] == pid)]
                    .groupby("reason_code")["amount"]
                    .sum()
                    .sort_values()
                    .head(3)
                    .reset_index()
                    .to_dict(orient="records")
                )

            refund_top.append(
                {
                    "product_id": pid,
                    "product_name": pinfo.get("product_name"),
                    "seller_id": pinfo.get("seller_id"),
                    "delta_refund": float(row["delta_refund"]),
                    "today_refund": float(r_today.reindex([pid], fill_value=0).iloc[0]),
                    "yday_refund": float(r_yday.reindex([pid], fill_value=0).iloc[0]),
                    "top_reasons": reasons,
                }
            )
    else:
        refund_top = []

    return {
        "date": str(today),
        "compare_to": str(yday),
        "kpis": {
            "gross_today": gross_today,
            "gross_yday": gross_yday,
            "gross_delta": gross_today - gross_yday,
            "refund_today": refund_today,
            "refund_yday": refund_yday,
            "refund_delta": refund_today - refund_yday,
            "net_today": net_today,
            "net_yday": net_yday,
            "net_delta": net_today - net_yday,
        },
        "drivers": {
            "gross_increase_top": gross_top,
            "refund_worsen_top": refund_top,
        },
    }


BRIEFING_JSON_SCHEMA = {
    "name": "daily_briefing",
    "schema": {
        "type": "object",
        "additionalProperties": False,
        "properties": {
            "headline": {"type": "string"},
            "key_findings": {
                "type": "array",
                "items": {
                    "type": "object",
                    "additionalProperties": False,
                    "properties": {
                        "finding": {"type": "string"},
                        "supporting_data": {
                            "oneOf": [
                                {"type": "object", "additionalProperties": True},
                                {"type": "array", "items": {"type": "object", "additionalProperties": True}},
                            ]
                        },
                    },
                    "required": ["finding"],
                },
                "minItems": 3,
                "maxItems": 5,
            },
            "actions": {
                "type": "array",
                "items": {
                    "type": "object",
                    "additionalProperties": False,
                    "properties": {
                        "title": {"type": "string"},
                        "why": {"type": "string"},
                        "expected_impact": {"type": "string"},
                    },
                    "required": ["title", "why"],
                },
                "minItems": 2,
                "maxItems": 4,
            },
        },
        "required": ["headline", "key_findings", "actions"],
    },
    "strict": True,
}

def generate_briefing(evidence: dict, model: str = "gpt-4o-mini") -> dict:
    client = _client()

    system = (
        "You are an operations analyst for an ecommerce CEO. "
        "Use ONLY the provided evidence. Do not invent facts. "
        "Respond entirely in Korean (headline, key_findings, actions). "
        "Return ONLY valid JSON. No markdown, no extra text."
    )

    user = {
        "task": "í•œê¸€ë¡œ ì¼ì¼ ë¸Œë¦¬í•‘ê³¼ ì•¡ì…˜ í”Œëœì„ ì‘ì„±í•˜ì„¸ìš”. ê° key_findingë§ˆë‹¤ ê·¸ ê·¼ê±°ê°€ ë˜ëŠ” evidenceë¥¼ ì •í˜• ë°ì´í„°ë¡œ ìš”ì•½í•´ supporting_dataì— ë„£ì–´ ì£¼ì„¸ìš”.",
        "output_schema": {
            "headline": "string (í•œê¸€)",
            "key_findings": [
                {
                    "finding": "string (í•œê¸€, 3~5ê°œ)",
                    "supporting_data": "object ë˜ëŠ” object[] â€” í•´ë‹¹ findingì˜ ê·¼ê±°ê°€ ë˜ëŠ” ìˆ˜ì¹˜/ë°ì´í„°. í‘œë¡œ ë³´ì—¬ì¤„ ìˆ˜ ìˆê²Œ í‚¤-ê°’ ê°ì²´ í•˜ë‚˜ ë˜ëŠ” í–‰ ë°°ì—´ë¡œ ìš”ì•½. ì»¬ëŸ¼ëª…ì€ ë°˜ë“œì‹œ 'ê¸°ì¤€ì¼'(ë¹„êµì¼ ê°’) ì‚¬ìš©. ì˜ˆ: {\"êµ¬ë¶„\":\"ìˆœë§¤ì¶œ\", \"ì˜¤ëŠ˜\":1150, \"ê¸°ì¤€ì¼\":1000, \"ì¦ê°\":150} ë˜ëŠ” [{\"ì¸í”Œë£¨ì–¸ì„œ\":\"A\", \"ë§¤ì¶œì¦ê°€\":100}, ...]"
                }
            ],
            "actions": [
                {"title": "string (í•œê¸€)", "why": "string (í•œê¸€)", "expected_impact": "string (í•œê¸€, optional)"}
            ]
        },
        "evidence": evidence
    }

    # chat.completionsëŠ” ê±°ì˜ ëª¨ë“  ë²„ì „ì—ì„œ ë™ì‘
    resp = client.chat.completions.create(
        model=model,
        messages=[
            {"role": "system", "content": system},
            {"role": "user", "content": json.dumps(user, ensure_ascii=False)}
        ],
        temperature=0.2
    )

    text = resp.choices[0].message.content.strip()

    # í˜¹ì‹œ ì•ë’¤ì— ì¡í…ìŠ¤íŠ¸ ë¶™ìœ¼ë©´ JSON ë¶€ë¶„ë§Œ ìµœëŒ€í•œ ì¶”ì¶œ
    start = text.find("{")
    end = text.rfind("}")
    if start == -1 or end == -1 or end <= start:
        raise RuntimeError(f"Model did not return JSON. Output was:\n{text}")

    return json.loads(text[start:end+1])


def generate_iv_report(components: Dict[str, Any], model: str = "gpt-4o") -> dict:
    """
    IV ë¦¬í¬íŠ¸ ìƒì„± (CEOìš©)
    IV ê¸°ë°˜ ì°¨ì´ ë¶„ì„ êµ¬ì„±ìš”ì†Œë¥¼ LLMì— ë³´ë‚´ ë¦¬í¬íŠ¸ í˜•ì‹ìœ¼ë¡œ ìƒì„±.
    components: report_tables.build_components_for_llm() ë°˜í™˜ê°’.
    ì´ë§¤ì¶œÂ·ì´ë¹„ìš©Â·ìˆœì´ìµ ë³€í™”ë¥¼ í•¨ê»˜ ë¶„ì„í•˜ê³ , ë§¤ì¶œ/ë¹„ìš© ë°©í–¥ì— ë”°ë¼ ë³´ì™„Â·ê°•í™” ì•¡ì…˜ í”Œëœì„ ìš”ì²­í•œë‹¤.
    - í•µì‹¬: 'ë§¤ì¶œ ê²¬ì¸ì(í•„ìˆ˜ ì¸ìš©): ...' ë¼ì¸ì„ ë³¸ë¬¸ ì²« ë¬¸ë‹¨ì— ê·¸ëŒ€ë¡œ í¬í•¨í•˜ë„ë¡ ê°•ì œ
    - ë§¤ì¶œâ†‘ì´ë©´ Î”ë§¤ì¶œ ê¸°ë°˜ ë“œë¼ì´ë²„ë¥¼ KPI í•µì‹¬ì›ì¸ ë¶„ì„ì˜ 1ìˆœìœ„ë¡œ ì‚¬ìš©
    - IVëŠ” 'ì™œ' ì„¤ëª…(êµ¬ì¡° ë³€í™”)ë¡œë§Œ ì‚¬ìš©
    """
    context = build_llm_context(components)

    prompt = f"""
ì•„ë˜ ë°ì´í„°ë§Œ ì‚¬ìš©í•´ì„œ CEOìš© IV ê¸°ë°˜ ë¦¬í¬íŠ¸ë¥¼ ì‘ì„±í•˜ë¼. ì œê³µëœ ìˆ«ì ì™¸ì˜ ìˆ˜ì¹˜ëŠ” ì‚¬ìš© ê¸ˆì§€.

---
{context}
---

### ì‘ì„± í˜•ì‹

**KPI ë³€í™” í•µì‹¬ì›ì¸ ë¶„ì„** â€” ê° ë¬¸ì¥ì— ë°˜ë“œì‹œ ìœ„ KEY NUMBERS ë˜ëŠ” ìƒì„¸í‘œì˜ ìˆ˜ì¹˜ê°€ ë“¤ì–´ê°€ì•¼ í•¨.
- ì¢‹ì€ ì˜ˆì‹œ(ì´ë ‡ê²Œ ì¨ë¼): "í™˜ë¶ˆì•¡ì´ ê¸°ì¤€ì¼ -50ë§Œ ì›ì—ì„œ ì˜¤ëŠ˜ -144ë§Œ ì›ìœ¼ë¡œ ì•½ 2.9ë°° ì¦ê°€(IV 25.3)í–ˆë‹¤. ì´ë¡œ ì¸í•´ ìˆœì´ìµì´ ì•½ 94ë§Œ ì› ê¹ì˜€ê³ , ë°©ì¹˜ ì‹œ ì›” -2,800ë§Œ ì› ìˆ˜ì¤€ ë¦¬ìŠ¤í¬ê°€ ìˆë‹¤."
- ë‚˜ìœ ì˜ˆì‹œ(ê¸ˆì§€): "í™˜ë¶ˆì´ ëŠ˜ì–´ë‚˜ ì£¼ì˜ê°€ í•„ìš”í•©ë‹ˆë‹¤.", "ë¶„ì„ì´ í•„ìš”í•©ë‹ˆë‹¤."

**ì•¡ì…˜ í”Œëœ** â€” êµ¬ì²´ì  í–‰ë™(WHAT)ë§Œ. ì‹œê°„(ì–¸ì œê¹Œì§€)Â·ëˆ„êµ¬(íŒ€/ë‹´ë‹¹ì) ëª…ì‹œ ê¸ˆì§€. ì˜ˆ: "í™˜ë¶ˆ ì‚¬ìœ  í™•ì¸ ì™„ë£Œ"

**ë¦¬ìŠ¤í¬** â€” ë°˜ë“œì‹œ ì› ë‹¨ìœ„ë¡œ ë. ì˜ˆ: "ë°©ì¹˜ ì‹œ ì›” ì•½ -2,800ë§Œ ì› ì¶”ê°€ ì†ì‹¤ ì¶”ì •."

**ì£¼ëª© íŒ¨í„´**(ë§¤ì¶œâ†‘ ìˆœì´ìµâ†“ ë˜ëŠ” ë§¤ì¶œâ†“ ìˆœì´ìµâ†‘)ì´ ìˆìœ¼ë©´ "í‘œë©´ìƒ ì•ˆì •ì ìœ¼ë¡œ ë³´ì´ì§€ë§Œ ì‹¤ì œë¡œëŠ”â€¦"ìœ¼ë¡œ ì¸ê³¼ë¥¼ ëª…ì‹œí•  ê²ƒ.

### ì œì¶œ ì „ ì²´í¬
- [ ] ëª¨ë“  ë¬¸ì¥ì— ìˆ˜ì¹˜ 1ê°œ ì´ìƒ?
- [ ] ìƒí’ˆ(ìƒí’ˆëª…) IV ìƒì„¸ê°€ ë°ì´í„°ì— ìˆìœ¼ë©´ KPI ë³€í™” í•µì‹¬ì›ì¸ ë¶„ì„ì— ë°˜ë“œì‹œ ìƒí’ˆë³„ ê¸°ì—¬(ìƒí’ˆëª…, ìˆ˜ì¹˜) í¬í•¨?
- [ ] ëª¨ë“  ì•¡ì…˜ì€ êµ¬ì²´ì  í–‰ë™(WHAT)ë§Œ. ì‹œê°„Â·ëˆ„êµ¬/íŒ€ ëª…ì‹œ ê¸ˆì§€
- [ ] ëª¨ë“  ë¦¬ìŠ¤í¬ì— ì›(â‚©) í‘œê¸°?
- [ ] "ë¶„ì„ì´ í•„ìš”í•©ë‹ˆë‹¤", "ê²€í† í•˜ì„¸ìš”" ê°™ì€ ëª¨í˜¸ í‘œí˜„ ì—†ìŒ?

ì•„ë˜ JSONë§Œ ì¶œë ¥. ë§ˆí¬ë‹¤ìš´Â·ì„¤ëª… ì—†ì´. sectionsëŠ” 2ê°œë§Œ: KPI ë³€í™” í•µì‹¬ì›ì¸ ë¶„ì„, ìš°ì„ ìˆœìœ„ë³„ ì•¡ì…˜ í”Œëœ.
ìš°ì„ ìˆœìœ„ë³„ ì•¡ì…˜ í”Œëœì€ ë°˜ë“œì‹œ actions ë°°ì—´ì— 1ìˆœìœ„, 2ìˆœìœ„ 2ê°œë§Œ ë„£ì–´ë¼.
{{
  "headline": "í•œì¤„ ìš”ì•½ 30ì ì´ë‚´ (ìˆ˜ì¹˜ í¬í•¨)",
  "sections": [
    {{ "title": "KPI ë³€í™” í•µì‹¬ì›ì¸ ë¶„ì„", "body": "ìœ„ ì˜ˆì‹œì²˜ëŸ¼ ìˆ˜ì¹˜+ì¸ê³¼+ë¦¬ìŠ¤í¬(ì›) í¬í•¨ ë³¸ë¬¸" }},
    {{
      "title": "ìš°ì„ ìˆœìœ„ë³„ ì•¡ì…˜ í”Œëœ",
      "body": "ì „ì²´ ì•¡ì…˜ ìš”ì•½ ë¬¸ë‹¨",
      "actions": [
        {{ "label": "1ìˆœìœ„", "action": "êµ¬ì²´ ì•¡ì…˜ (WHATë§Œ, ì‹œê°„Â·ëˆ„êµ¬ ëª…ì‹œ ê¸ˆì§€)" }},
        {{ "label": "2ìˆœìœ„", "action": "êµ¬ì²´ ì•¡ì…˜" }}
      ]
    }}
  ]
}}
"""
    print("=== LLMì— ë“¤ì–´ê°€ëŠ” ì»¨í…ìŠ¤íŠ¸ ===")
    print(context)
    print("=== ë ===")

    client = _client()
    system = (
        "You are a senior analyst for a Korean fashion e-commerce company.\n"
        "You MUST follow the rules. If you violate them, the report is invalid.\n"
    )
    resp = client.chat.completions.create(
        model=model,
        messages=[
            {
                "role": "system",
                "content": """You are a senior Korean fashion e-commerce analyst writing for the CEO.

MANDATORY rules - violating any = bad report:
1. Every sentence must contain AT LEAST ONE specific number from the data
2. Always state: what happened â†’ why it matters â†’ what happens if ignored
3. Actions must state WHAT only. Do NOT specify WHEN (time/deadline) or WHO (team/person)
4. Never use vague words like "ë¶„ì„ì´ í•„ìš”í•©ë‹ˆë‹¤", "ê²€í† í•˜ì„¸ìš”" - give the actual answer
5. If two factors cancel each other out, explicitly say "í‘œë©´ìƒ ì•ˆì •ì ìœ¼ë¡œ ë³´ì´ì§€ë§Œ ì‹¤ì œë¡œëŠ”..."
6. End every risk with a specific estimated impact in Korean won

Respond ONLY in valid JSON. Korean language.

""",
            },
            {"role": "user", "content": prompt},
        ],
        temperature=0.1,
    )
    text = resp.choices[0].message.content.strip()
    start = text.find("{")
    end = text.rfind("}")
    if start == -1 or end <= start:
        return {"headline": text[:500], "sections": []}
    report = json.loads(text[start : end + 1])
    return report


def build_db_context_for_qa(
    orders: Optional[pd.DataFrame] = None,
    items: Optional[pd.DataFrame] = None,
    adj: Optional[pd.DataFrame] = None,
    products: Optional[pd.DataFrame] = None,
    max_rows: int = 150,
) -> str:
    """
    ì§ˆì˜ì‘ë‹µ ì‹œ ì „ì²´ DBë¥¼ í›‘ì–´ì„œ ë‹µí•  ìˆ˜ ìˆë„ë¡ í…Œì´ë¸”ë³„ ìŠ¤í‚¤ë§ˆ + ìƒ˜í”Œ ë¬¸ìì—´ ìƒì„±.
    ì˜ˆ: ìƒí’ˆ P010ì„ íŒŒëŠ” ì…€ëŸ¬ëŠ” products.csvì˜ seller_idì—ì„œ í™•ì¸ ê°€ëŠ¥í•˜ë„ë¡ í¬í•¨.
    """
    lines = ["## ì „ì²´ DB ê°œìš” (ì§ˆì˜ì‘ë‹µ ì‹œ ì´ ë°ì´í„°ë¥¼ í›‘ì–´ì„œ ë‹µë³€í•  ê²ƒ)"]

    def _sample(df: pd.DataFrame, name: str, cols: Optional[List[str]] = None, n: int = max_rows) -> None:
        if df is None or df.empty:
            return
        lines.append(f"### {name}")
        lines.append("ì»¬ëŸ¼: " + ", ".join(df.columns.tolist()))
        use = df[cols] if cols and all(c in df.columns for c in cols) else df
        lines.append(use.head(n).to_string(index=False))
        lines.append("")

    if products is not None and not products.empty:
        lines.append("### products (ìƒí’ˆ ì •ë³´). ì˜ˆ: ìƒí’ˆ P010ì„ íŒŒëŠ” ì…€ëŸ¬ â†’ product_idë¡œ í–‰ì„ ì°¾ê³ , seller_id ì»¬ëŸ¼ì´ ì…€ëŸ¬ ì •ë³´.")
        lines.append("ì»¬ëŸ¼: " + ", ".join(products.columns.tolist()))
        cols = [c for c in ["product_id", "seller_id", "product_name"] if c in products.columns]
        sub = products[cols] if cols else products.iloc[:, :6]
        lines.append(sub.head(max_rows).to_string(index=False))
        lines.append("")

    if orders is not None and not orders.empty:
        _sample(orders, "orders (ì£¼ë¬¸)", n=max_rows)

    if items is not None and not items.empty:
        _sample(items, "order_items (ì£¼ë¬¸ë³„ ìƒí’ˆ/ë§¤ì¶œ)", n=max_rows)

    if adj is not None and not adj.empty:
        _sample(adj, "adjustments (í™˜ë¶ˆ ë“±)", n=max_rows)

    return "\n".join(lines)

def answer_report_question(
    report, context, messages,
    orders=None, items=None, adj=None, products=None,
    db_context: str = "",
    model: str = "gpt-4o",  # â† mini â†’ gpt-4o
) -> tuple:
    client = _client()
    df_result = None
    sql_result = ""
    if items is not None:
        try:
            conn = _load_sqlite(orders, items, adj, products)
            schema = _get_schema(conn)
            
            # products ì „ì²´ë¥¼ schemaì— ì¶”ê°€ (ì…€ëŸ¬ ì •ë³´ ì˜¤ë‹µ ë°©ì§€)
            if products is not None:
                schema += f"\n\n## products ì „ì²´ ë°ì´í„° (seller_id í™•ì¸ìš©)\n{products.to_string(index=False)}"
            
            question = messages[-1]["content"]
            sql = _text_to_sql(question, schema)
            
            # SQL ì‹¤í–‰
            df_result = pd.read_sql_query(sql, conn)
            
            if not df_result.empty:
                sql_result = (
                    f"\n## ì‹¤ì‹œê°„ DB ì¡°íšŒ ê²°ê³¼"
                    f"\nì‹¤í–‰ SQL: {sql}"
                    f"\nê²°ê³¼:\n{df_result.to_string(index=False)}"
                    f"\nâ€» ìœ„ ì¡°íšŒ ê²°ê³¼ê°€ ì‚¬ì‹¤ì´ë©°, ì´ ìˆ«ìë§Œ ì‚¬ìš©í•  ê²ƒ. ë‹¤ë¥¸ ìˆ«ì ì‚¬ìš© ê¸ˆì§€."
                )
        except Exception as e:
            sql_result = f"\n## DB ì¡°íšŒ ì‹¤íŒ¨: {e}"

    system = (
        "You are a senior analyst for a Korean fashion e-commerce company.\n"
        "RULES:\n"
        "1. 'ì‹¤ì‹œê°„ DB ì¡°íšŒ ê²°ê³¼'ê°€ ìˆìœ¼ë©´ ê·¸ ìˆ«ìë§Œ ì‚¬ìš©í•´ë¼. ì ˆëŒ€ ì¶”ì¸¡í•˜ì§€ ë§ˆë¼.\n"
        "2. DB ì¡°íšŒ ê²°ê³¼ê°€ ì—†ìœ¼ë©´ ë¦¬í¬íŠ¸ì™€ ë¶„ì„ ì»¨í…ìŠ¤íŠ¸ë§Œ ì‚¬ìš©í•´ë¼.\n"
        "3. ëª¨ë¥´ë©´ 'ë°ì´í„°ì—ì„œ í™•ì¸ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤'ë¼ê³  í•´ë¼. ì ˆëŒ€ ë§Œë“¤ì–´ë‚´ì§€ ë§ˆë¼.\n"
        "4. í•œêµ­ì–´ë¡œ ë‹µë³€. ê°„ê²°í•˜ê³  ì•¡ì…˜ ì¤‘ì‹¬ìœ¼ë¡œ."
    )
    
    report_text = "## ë¦¬í¬íŠ¸\n" + report.get("headline", "") + "\n\n"
    for s in report.get("sections", []):
        report_text += f"### {s.get('title','')}\n{s.get('body','')}\n\n"
    report_text += "\n## ë¶„ì„ ì»¨í…ìŠ¤íŠ¸\n" + context
    report_text += sql_result

    api_messages = [{"role": "system", "content": system + "\n\n" + report_text}]
    for m in messages[-10:]:
        api_messages.append({"role": m["role"], "content": m["content"]})

    resp = client.chat.completions.create(model=model, messages=api_messages, temperature=0)
    reply = resp.choices[0].message.content.strip()
    return (reply, df_result)